---
title: "July 2019 TWAU Shokunin"
author: "Kevin Yeung"
date: "21/07/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

I use the ```jpeg``` library to read in the RGB values of each image. The image is then divided into different regions. In each region, the RGB value of the centre 4x4 square is taken as a feature.

For each city, its images are split into training and validation sets (30:70). The following is the function definitions for extracting pixels and splitting the images into training and test sets.

```{r function-definitions}
install.packages("jpeg")
install.packages("dplyr")
install.packages("party")
library(jpeg)
library(dplyr)
library(party)
library(randomForest)

getPixelValues <- function(pixels) {
  c(pixels[3:6,7:10], pixels[3:6,24:27], pixels[3:6,39:42], pixels[3:6,54:57],
    pixels[11:14,7:10], pixels[11:14,24:27], pixels[11:14,39:42], pixels[11:14,54:57],
    pixels[19:22,7:10], pixels[19:22,24:27], pixels[19:22,39:42], pixels[19:22,54:57],
    pixels[27:30,7:10], pixels[27:30,24:27], pixels[27:30,39:42], pixels[27:30,54:57])
}

getR <- function(img) {
  getPixelValues(img[,,1])
}
getG <- function(img) {
  getPixelValues(img[,,2])
}
getB <- function(img) {
  getPixelValues(img[,,3])
}

getImageFeatures <- function(img) {
  r <- getR(img)
  g <- getG(img)
  b <- getB(img)
  df <- data.frame(t(c(r,g,b)))
  
  df
}

extractAndLabelImages <- function(label) {
  filenames <- list.files(paste("./synimg/train/", label, sep = ""), pattern = "*.jpg", full.names = TRUE)
  
  accum <- data.frame()
  
  results <- lapply(filenames, function(f) {
    img <- readJPEG(f)
    
    imgRgb <- getImageFeatures(img)
    imgRgb <- cbind("city" = label, imgRgb)
    
    rbind(accum, imgRgb)
  })

  results <- bind_rows(results)
}

splitTrainingAndValidationSets <- function(images) {
  list(images[1:3000,], images[3001:10000,])
}
```

Here, images in each city are loaded, and split into training and validation data frames.

```{r read-images}
cities <- list("Beijing", "Brisbane", "Geneva", "HongKong", "Luanda", "Melbourne", "Seoul", "Singapore", "Sydney", "Zurich")

training <- data.frame()
validation <- data.frame()

for (city in cities) {
  print(paste("reading", city))
  df <- extractAndLabelImages(city)
  tv <- splitTrainingAndValidationSets(df)
  
  training <- rbind(training, tv[[1]])
  validation <- rbind(validation, tv[[2]])
}
```

Here, I train two models - a simple decision tree and a random forest.

```{r training}
tree <- ctree(city ~ ., data = training)
save(tree, file = "cities.tree.model")

forest <- randomForest(city ~ ., data = training)
save(forest, file = "cities.forest.model")
```

The two models are tested using the validation set. The random forest, as expected, out-performs the tree.

```{r validation}
predict_cities <- function(method, model, data) {
  p <- predict(model, data)
  predicted <- cbind(p, data)

  correct <- predicted[predicted$p == predicted$city, ]
  print(paste(method, "% correct = ", nrow(correct) / nrow(predicted) * 100))
}

predict_cities("decision tree", tree, validation)
predict_cities("random forest", forest, validation)
```

And here's using the random forest to predict the final test set.

```{r predict}
test_csv <- read.csv("./synimg/test/data_nostyle.csv")

extractTestImages <- function() {
  filenames <- test_csv$filepath

  accum <- data.frame()
  
  results <- lapply(filenames, function(f) {
    filepath <- paste("./", f, sep = "")

    img <- readJPEG(filepath)

    imgRgb <- getImageFeatures(img)

    rbind(accum, imgRgb)
  })

  bind_rows(results)
}

test_images_pixels <- extractTestImages()

test_csv$predicted <- predict(forest, test_images_pixels)

head(test_csv)

write.csv(test_csv, file = "predicted.csv", quote = FALSE)

```

